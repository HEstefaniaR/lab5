{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones iniciales: (5268, 14)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5268 entries, 0 to 5267\n",
            "Data columns (total 14 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   index         5268 non-null   int64  \n",
            " 1   Date          5268 non-null   object \n",
            " 2   Time          3049 non-null   object \n",
            " 3   Location      5248 non-null   object \n",
            " 4   Operator      5250 non-null   object \n",
            " 5   Flight #      1069 non-null   object \n",
            " 6   Route         3561 non-null   object \n",
            " 7   Type          5241 non-null   object \n",
            " 8   Registration  4933 non-null   object \n",
            " 9   cn/In         4040 non-null   object \n",
            " 10  Aboard        5246 non-null   float64\n",
            " 11  Fatalities    5256 non-null   float64\n",
            " 12  Ground        5246 non-null   float64\n",
            " 13  Summary       4878 non-null   object \n",
            "dtypes: float64(3), int64(1), object(10)\n",
            "memory usage: 576.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/Airplane_Crashes_and_Fatalities_Since_1908.csv\")\n",
        "print(\"Dimensiones iniciales:\", df.shape)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# # 2. Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Estadísticas descriptivas ===\n",
            "            index       Aboard   Fatalities       Ground\n",
            "count  5268.00000  5246.000000  5256.000000  5246.000000\n",
            "mean   2633.50000    27.554518    20.068303     1.608845\n",
            "std    1520.88494    43.076711    33.199952    53.987827\n",
            "min       0.00000     0.000000     0.000000     0.000000\n",
            "25%    1316.75000     5.000000     3.000000     0.000000\n",
            "50%    2633.50000    13.000000     9.000000     0.000000\n",
            "75%    3950.25000    30.000000    23.000000     0.000000\n",
            "max    5267.00000   644.000000   583.000000  2750.000000\n",
            "\n",
            "=== Estadísticas categóricas ===\n",
            "              Date   Time           Location  Operator Flight #     Route  \\\n",
            "count         5268   3049               5248      5250     1069      3561   \n",
            "unique        4753   1005               4303      2476      724      3243   \n",
            "top     09/11/2001  15:00  Sao Paulo, Brazil  Aeroflot        -  Training   \n",
            "freq             4     32                 15       179       67        81   \n",
            "\n",
            "                Type Registration cn/In                  Summary  \n",
            "count           5241         4933  4040                     4878  \n",
            "unique          2446         4905  3707                     4673  \n",
            "top     Douglas DC-3           49   178  Crashed during takeoff.  \n",
            "freq             334            3     6                       15  \n",
            "\n",
            "=== Valores únicos por columna ===\n",
            "index           5268\n",
            "Date            4753\n",
            "Time            1005\n",
            "Location        4303\n",
            "Operator        2476\n",
            "Flight #         724\n",
            "Route           3243\n",
            "Type            2446\n",
            "Registration    4905\n",
            "cn/In           3707\n",
            "Aboard           239\n",
            "Fatalities       191\n",
            "Ground            50\n",
            "Summary         4673\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Estadísticas básicas\n",
        "print(\"\\n=== Estadísticas descriptivas ===\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n=== Estadísticas categóricas ===\")\n",
        "print(df.describe(include='object'))\n",
        "\n",
        "print(\"\\n=== Valores únicos por columna ===\")\n",
        "print(df.nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Completitud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Valores nulos ===\n",
            "index              0\n",
            "Date               0\n",
            "Time            2219\n",
            "Location          20\n",
            "Operator          18\n",
            "Flight #        4199\n",
            "Route           1707\n",
            "Type              27\n",
            "Registration     335\n",
            "cn/In           1228\n",
            "Aboard            22\n",
            "Fatalities        12\n",
            "Ground            22\n",
            "Summary          390\n",
            "dtype: int64\n",
            "\n",
            "Porcentaje global de valores faltantes: 13.83%\n",
            "Filas con más del 50% nulos: 6\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Valores nulos ===\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "total_missing = df.isnull().sum().sum()\n",
        "total_cells = df.shape[0] * df.shape[1]\n",
        "print(f\"\\nPorcentaje global de valores faltantes: {round((total_missing / total_cells) * 100, 2)}%\")\n",
        "\n",
        "# Filas con más de 50% valores nulos\n",
        "rows_many_missing = df[df.isnull().sum(axis=1) > (df.shape[1] / 2)]\n",
        "print(f\"Filas con más del 50% nulos: {rows_many_missing.shape[0]}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2.2 Fechas y tiempos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fechas inválidas: 0\n",
            "Fecha mínima: 1908-09-17 00:00:00\n",
            "Fecha máxima: 2009-06-08 00:00:00\n",
            "Tiempos con formato inválido: 19\n"
          ]
        }
      ],
      "source": [
        "# Convertir a datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "fecha_min, fecha_max = pd.to_datetime('1908-01-01'), pd.to_datetime('2025-09-17')\n",
        "invalid_dates = df[(df['Date'] < fecha_min) | (df['Date'] > fecha_max) | df['Date'].isna()]\n",
        "\n",
        "print(f\"\\nFechas inválidas: {len(invalid_dates)}\")\n",
        "print(\"Fecha mínima:\", df['Date'].min())\n",
        "print(\"Fecha máxima:\", df['Date'].max())\n",
        "\n",
        "# Validar formato de hora HH:MM\n",
        "invalid_time = df['Time'].dropna()[~df['Time'].dropna().str.match(r'^\\d{2}:\\d{2}$')]\n",
        "print(f\"Tiempos con formato inválido: {len(invalid_time)}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2.3 Valores atípicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aboard: negativos=0, máximo=644.0\n",
            "Fatalities: negativos=0, máximo=583.0\n",
            "Ground: negativos=0, máximo=2750.0\n",
            "Filas con Fatalities > Aboard: 0\n"
          ]
        }
      ],
      "source": [
        "numeric_cols = ['Aboard', 'Fatalities', 'Ground']\n",
        "\n",
        "for col in numeric_cols:\n",
        "    neg_count = (df[col] < 0).sum()\n",
        "    print(f\"{col}: negativos={neg_count}, máximo={df[col].max()}\")\n",
        "\n",
        "# Fatalities no puede ser mayor que Aboard\n",
        "invalid_fatalities = df[df['Fatalities'] > df['Aboard']]\n",
        "print(f\"Filas con Fatalities > Aboard: {len(invalid_fatalities)}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2.4 Duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicados exactos: 0\n",
            "Duplicados por clave ['Date', 'Location', 'Operator', 'Type']: 0\n"
          ]
        }
      ],
      "source": [
        "exact_dups = df.duplicated().sum()\n",
        "print(f\"Duplicados exactos: {exact_dups}\")\n",
        "\n",
        "key_cols = ['Date', 'Location', 'Operator', 'Type']\n",
        "dup_key = df.duplicated(subset=key_cols, keep=False).sum()\n",
        "print(f\"Duplicados por clave {key_cols}: {dup_key}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 3. Limpieza de Datos\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.1 Eliminar columnas innecesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columna 'Flight #' eliminada.\n"
          ]
        }
      ],
      "source": [
        "df.drop(columns=['Flight #'], inplace=True, errors='ignore')\n",
        "print(\"Columna 'Flight #' eliminada.\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.2 Limpiar columna Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_time(time_str):\n",
        "    if pd.isna(time_str) or time_str.strip() == '':\n",
        "        return 'Not Specified'\n",
        "    time_str = time_str.strip()\n",
        "    if re.match(r'^\\d{1}:\\d{2}$', time_str):  # 7:30 -> 07:30\n",
        "        return '0' + time_str\n",
        "    return time_str if re.match(r'^\\d{2}:\\d{2}$', time_str) else 'Invalid'\n",
        "\n",
        "df['Time_clean'] = df['Time'].apply(clean_time)\n",
        "\n",
        "# Reemplazar \"Not Specified\" por la moda\n",
        "time_mode = df[df['Time_clean'] != 'Not Specified']['Time_clean'].mode()[0]\n",
        "df['Time_clean'] = df['Time_clean'].replace('Not Specified', time_mode)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.3 Normalizar texto categórico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/mc/2gfzh5v563gcj4y_t_x5lrmc0000gn/T/ipykernel_4591/3784367512.py:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[category_cols] = df[category_cols].applymap(normalize_text)\n"
          ]
        }
      ],
      "source": [
        "def normalize_text(text):\n",
        "    return str(text).strip().lower() if pd.notna(text) and text.strip() != '' else 'not specified'\n",
        "\n",
        "category_cols = ['Location', 'Operator', 'Route', 'Type', 'Registration', 'cn/In', 'Summary']\n",
        "df[category_cols] = df[category_cols].applymap(normalize_text)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.4 Estandarizar Operator y Location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_operator(op):\n",
        "    mappings = {\n",
        "        r'aeroflot': 'Aeroflot',\n",
        "        r'united airlines': 'United Airlines',\n",
        "        r'military - u.s. army|military - u.s. air force': 'Military USA',\n",
        "        r'air france': 'Air France',\n",
        "        r'american airlines': 'American Airlines',\n",
        "        r'pan am': 'Pan Am'\n",
        "    }\n",
        "    for pattern, replacement in mappings.items():\n",
        "        op = re.sub(pattern, replacement, op, flags=re.IGNORECASE)\n",
        "    return op.title()\n",
        "\n",
        "df['Operator'] = df['Operator'].apply(clean_operator)\n",
        "\n",
        "# Limpiar Location\n",
        "def clean_location(loc):\n",
        "    loc = re.sub(r'\\(.*?\\)|\\[.*?\\]', '', loc)\n",
        "    loc = re.sub(r'\\s+', ' ', loc).strip()\n",
        "    return loc.title()\n",
        "\n",
        "df['Location'] = df['Location'].apply(clean_location)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.5 Manejar valores nulos numéricos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Ground'] = df['Ground'].fillna(0)\n",
        "\n",
        "# Medianas por tipo\n",
        "aboard_median = df.groupby('Type')['Aboard'].transform('median')\n",
        "df['Aboard'] = df['Aboard'].fillna(aboard_median).fillna(df['Aboard'].median())\n",
        "\n",
        "fatalities_median = df.groupby('Type')['Fatalities'].transform('median')\n",
        "df['Fatalities'] = df['Fatalities'].fillna(fatalities_median).fillna(df['Fatalities'].median())\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.6 Ajustar tipos finales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Aboard'] = df['Aboard'].astype(int)\n",
        "df['Fatalities'] = df['Fatalities'].astype(int)\n",
        "df['Ground'] = df['Ground'].astype(int)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3.7 Columnas derivadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Year'] = df['Date'].dt.year\n",
        "df['Decade'] = (df['Year'] // 10) * 10\n",
        "\n",
        "# %% [markdown]\n",
        "# # 4. Dataset final limpio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Index'] not in index\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIndex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOperator\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRoute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegistration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcn/In\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAboard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFatalities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGround\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSummary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDecade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      5\u001b[0m df_final\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValores nulos finales:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, df_final\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
            "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Index'] not in index\""
          ]
        }
      ],
      "source": [
        "df_final = df[['Index', 'Date', 'Time_clean', 'Location', 'Operator', 'Route',\n",
        "               'Type', 'Registration', 'cn/In', 'Aboard', 'Fatalities', 'Ground',\n",
        "               'Summary', 'Year', 'Decade']].copy()\n",
        "\n",
        "df_final.info()\n",
        "print(\"\\nValores nulos finales:\\n\", df_final.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.head()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
